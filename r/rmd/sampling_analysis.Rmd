---
title: "Genralization analysis in deforestation and forest samples in Amazon Forest"
output: html_notebook
---
```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# Introduction

The Amazon forest is the largest rainforest in the world, and it has a vital role in the carbon cycle and climate regulation. The majority of the Amazon forest is in Brazil, about 60%. Since the end of 80 decade, the Brazilian government has maintained projects based on remote sensing images to monitor the region. PRODES, launched in 1988, is a project with global respect, and it was responsible for a considerable decrease in the deforestation rate in the 90s and the beginning of the 2000s. However, deforestation has increased over the past 15 years, which concerns the Brazilian government.

Even with the evolution of machine learning methods, the visual analysis of the images is the primary method in PRODES and other monitoring projects. For some reason, the region is covered by clouds almost all year, which can result in noise samples and a low number of images with soil information. Another reason is the variability of the samples observed in the region. The Amazon forest has a distinct response over a year and more; the forest may be different depending on the location, and this can result in multiple patterns. Also, deforestation only occurs occasionally, presenting distinct patterns to samples. So, a machine learning method to produce information can be complex.

Considering the sampling process in machine learning methods, understanding how samples behave spatial and temporal is fundamental to improving the results of machine learning methods. Therefore, this work aims to produce a statistical analysis of samples of deforestation and forest in the Amazon forest to understand how much the patterns are different in the deforest and forest classes. Also, we analyze different samples in space and time to verify how much is possible generalize a clustering method.

# Hypotheses

General

* Can use short time series to improve the generalization of model?
* Is there a relationship between samples in different region and time?
* Is it possible generate a generic clustering algorithm considering time and space variation?

Spatial

* Samples in different tile can be classify using an single tile as reference.
* The patterns are similar in different tiles.
* Is possible produce a ML model generic as possible to classify different region?

Temporal

* Samples in a specific time step can be used to classify samples in the future

* The seasonal behavior of time series happen in the next years

# Lybraries used

```{r lybraries}
library(cluster)
library(sits)
library(sitsdata)
library(dplyr)
library(factoextra)
library(data.table)
library(sf)
library(dtwclust)
source("../src/analysis_functions.R")
```


# Region of interest

Study area The selected study area cover three Brazil states: 'Rondonia', 'Amazonas' e 'Mato Grosso'. The major area is in the Rondonia State. Rondonia presented the fourth state with the most areas of deforestation in 2022, with 1480 km2. Also, the state has had the third-largest accumulated deforestation area (66103 km2) since 1988 (PRODES launch year). It makes the region a focus of attention for government authorities concerned with deforestation. Therefore, the region is a hotspot for illegal actions. Below is presented a code showing the study area location.

```{r, results='hide',fig.keep='all' }
federative_units <- sf::st_read("../../data/shp/uf_2020/uf_2020.shp")
roi <- sf::st_read("../../data/shp/roi_5x5/roi.shp")
brazilian_amazon <- sf::st_read("../../data/shp/brazilian_amazon/brazilian_legal_amazon.shp")
bdc_grid <- sf::st_read("../../data/shp/bdc_sm/bdc_sm_4326.shp")
ref_roi <- sf::st_read("../../data/shp/ref_roi/ref_roi.shp")

ggplot2::ggplot() + 
  ggplot2::geom_sf(data = federative_units) + 
  ggplot2::geom_sf(data = bdc_grid, alpha=1/10) + 
  ggplot2::geom_sf(data = brazilian_amazon, fill = "green",alpha = 1/5) +
  ggplot2::geom_sf(data = roi, fill = "red",alpha = 1/1.5) +
  ggplot2::geom_sf(data = ref_roi, fill = "black")
```

**Legend**

* Green - Legal Amazon Forest
* Red - Study area
* Black - Reference tile - 013015 (train area)
* White - BDC grid
* Gray - Federative Units

# Data

The samples using a PRODES map to define their geographic location (longitude and latitude) and S2_SEN2COR_10_16D_STK-1 BDC cube provide the time series values. PRODES methodology allows us to define forest samples where it is possible to define a single class sample over two consecutive years safely. Considering deforestation areas, it is impossible to ensure a single class sample over these two years because the land cover can change along the selected period, e.g., pasture. However, it is possible to conclude that there was deforestation at the beginning of the time series period, and the ground truth is not a primary forest in all periods. The samples have 265026 time series: 182146 in forest and 82880 deforested areas. The R code above imports the samples and show the first six samples.

```{r import samples }
samples <- readRDS("../../data/rds/samples/2018-2021/samples.rds")
head(samples)
```
# Statistical Analysis

Statistical analysis is a mathematical procedure to investigate trends, patterns and relationship through quantitative data. The method consists in collect data and summarize it using a descriptive statistics. To draw a valid conclusions using statistical analysis is important develop carefully the sampling procedure, use inferential statistics to test hypotheses, make estimates about the population to finally interpret and generalize your findings.

# General Analysis

The statistic analysis can allow us to understand the temporal and spatial behavior of the samples, showing patterns, trends, relationships, and variability using quantitative data. We will start presenting a summary of the bands' values by class. The data comprises sentinel observations, including twelve bands and two vegetation indexes. The code above summarizes the time series data along the time by class. In this summary, we can visualize basic statistical measurements for each band by class.

* Forest samples

```{r forest stats}
forest_samples <- samples[samples$label == "Forest",]
ts <- forest_samples$time_series
dt <- dt <- data.table::data.table(dplyr::bind_rows(ts))
summary(dt)
```

* Deforestation samples

```{r deforestation stats}
deforestation_samples <- samples[samples$label == "Deforestation",]
ts <- deforestation_samples$time_series
dt <- dt <- data.table::data.table(dplyr::bind_rows(ts))
summary(dt)
```

To all values, we can observe a distortion between the median/mean and the maximum and maximum value measured for both the deforestation and the forest class. In this summary, the measures consider all values independent of the date, so we do not consider the temporal characteristic of the samples. These distortions can indicate that the observed value can not correspond to the actual land cover value at some point in the period. Some reasons for this can be the presence of clouds, aerosol interference, or pixel saturation. The interquartile range shows slight variation, indicating that most observed values have a singular pattern.

# Variation band

Above is presented a box plot for each band.

```{r box plot samples, fig.width=9,fig.height=5, warning=FALSE}
plot_box(samples)
```
The interquartile variation is generally more significant for the Deforestation class than the Forest class, showing that the forest class presented a more homogeneous behavior. This behavior is expected considering the characteristics of the classes. The Amazon forest presents a massive tree concentration throughout the entire period. Meanwhile, deforestation is a non-homogeneous tree loss that can explain the variation, and the area can be another class, e.g., pasture. Still looking for the interquartile, the band variation is slight to all bands and slightly more significant to indexes. The bands B01 to B05 presented a slight variation considering the two classes. Contrasting Forest against Deforestation class, the band B12 to Forest class also presents a slight variation; meanwhile, the band B12 to Deforestation class presents more variation in comparison. The bands B06 to B11 present more variation in contrast to other bands. The indexes' variation is more considerable, mainly considering the deforestation class. The median for the bands presents less variation to the classes compared to indexes; this shows how these indexes highlight the vegetation. All bands presented many numbers of outliers. To analyze these behaviors, we will explore the temporal characteristics to verify if these observations can be retired or if these outliers represent a natural variation considering clouds, for example.

Now, we are analyzing the behavior of the bands, considering the time variation. To simplify the visualization of the charts, we analyzed the two indexes (NDVI and EVI). Above, we plot two charts of the median and the quartiles. The command above calculated some statistics from the sample data: Mean, Median, Quartil 25%, Quartil 75%, Median, Standard deviation, and Correlation.

```{r calc stats, warning=FALSE}
stats <- stats_ts(samples)
```

* NDVI and EVI (Plotting Median and Quartils)

```{r plot stats}
plot_stats(stats, c("Median", "Q25", "Q75"), c("NDVI", "EVI"))
```

Analyzing the graphs, we can observe that the forest samples present a behavior with less variation in the median value over time than the deforestation class. The interquartile range for deforestation samples is generally considerably more extensive than for forest samples. In addition, the interquartile distance is more diminutive in periods of drought, indicating that the lower presence of clouds in this period drastically reduces the variability of observed values. The median of the indices for the deforestation samples presents two characteristic peaks in the rainy season and two valleys in the dry season. As for the forest samples, it is also possible to identify these peaks and valleys for the same periods. However, the values have a lower variance, highlighting the more homogeneous behavior for the vegetation indices over time. By contrasting the indices, we can see that in the case of deforestation samples, the general behavior of the median is similar for both indices, with lower values for EVI and higher values for NDVI. As for the forest samples, we can identify an almost opposite behavior for the indices. When the value increases for the EVI, the median value decreases for the NDVI.

# Pattern analysis

In time series analysis, it is helpful to visualize the temporal patterns to understand the band variability over the period. The chart above presents a statistical approximation of the samples in a single plot with all available sentinel bands and two vegetation indexes. The patterns represent an additive model (GAM) to obtain a possible predictor.

The following code presents the function sits_patterns(). It uses the dtwSat R package to generate the patterns used in the plot.

```{r patterns}
patterns <- sits::sits_patterns(samples)
plot_patterns(patterns)
```

The resulting patterns allow us to analyze the behavior of the deforestation and Forest classes over two years of observations. The Forest class has less variation response than deforestation over the years; this shows that it should be possible to generate a reasonable separation between the classes. We can gain some insights into the expected classes by considering the vegetation indexes. The forest response is more homogeneous over the period with high values than the deforestation class, where the responses present high variation. Deforestation is the highest response occurring in the rainy season, with a considerable drop in the dry season. Contrasting the indexes, the deforestation response to NDVI and EVI presents a solid linear positive correlation. For the forest response, there is no strong linear correlation between the indexes.

# Intra-class band Correlation

The previous patterns are sound indicative of the class's behavior. Thus, their Correlation can support the previous analysis. The code below calculates the intra-class band correlation and plots it. Here, we desire to analyze numerically the relationship between the pattern bands of deforestation and Forest classes separately.

```{r inter class correlation, fig.width=9,fig.height=5, warning=FALSE}
cor <- corr_ts(patterns)
plot_corr_matrix(cor)
```

The intra-class Correlation of the band's patterns to forest patterns reveals a high positive correlation to all bands except the NDVI band, which presents a negative correlation to other bands. We can separate four groups with a high positive correlation in the deforestation class: 1 (B01 to B05), 2 (B06 to B09), 3 (B11 to B12), and 4 (NDVI and EVI). Analyze the groups against each other: Group 1 practically has no Correlation to other groups; Group 2 presents a negative correlation to 3 and a positive correlation to 4; Group 3 presents a negative Correlation to 4. The previous analysis covers group 4 correlation against other groups.

# Inter-class band Correlation

The code below calculates the inter-class band correlation and plots it. Here, we want to analyze the band patterns correlation class against class, comparing the respective band of deforestation patterns with forest patterns.

```{r intra class correlation}
df <- corr_classes(patterns)
ggplot2::ggplot(data=df, aes(x=Band, y=Correlation)) +
  ggplot2::geom_bar(stat="identity", fill="steelblue")+
  ggplot2::geom_text(aes(label=Correlation), vjust=-0.3, size=3.5)+
  ggplot2::theme_minimal()
```

The inter-class Correlation shows a high positive correlation between the band patterns B01, B02, B03, B04, and B05. And a negative correlation to bands B08 and EVI. The other bands practically presented no correlation between the patterns of the respective bands of forest class and deforestation class.


# Bands Analysis

The previous intra-class Correlation analysis reveals that some band patterns are highly correlated. Indicating that some patterns have almost the same information, making it redundant to include them in an ML model. Including these highly correlated patterns in a model can lead to a multicollinearity problem. To avoid this problem, we developed a strategy to select features based on correlation analysis (Intra-class and Inter-class analysis). Based on the Intra-class correlation information to each class, we observed four groups with a high positive correlation considering the deforestation class. Through that information, we select the following bands by groups.

* Group 1: Select band B04 because the band presents no correlation to other groups (Intra-class Correlation chart).

* Group 2: Select band B07 because the band presents the lowest Inter-class Correlation.

* Group 3: Select band B12 because the band presents the lowest Inter-class Correlation.

* Group 4: Select the bands NDVI and EVI. The NDVI negatively correlates to other bands considering the forest class (Intra-class Correlation chart), and the band presents the lowest Intra-class Correlation. The EVI is also an index vegetation that presents a similar behavior in the deforestation class and negatively correlates to NDVI in the forest class.

The analysis generates a list of selected bands (B05, B07, B11, NDVI, and EVI). The subsequent analysis uses this list of bands to verify how a hierarchical clustering method behaves with a distinct combination of the band list. In the other analysis, we use integral time series, all periods, and all sample coordinates. However, here, we select the first year of the period and the samples located on the central tile of the interest region because the subsequent analysis aims to test the generalization of the generated models. The code below generates all possible band list combinations and produces one model by combination using the same hierarchical cluster configuration.

```{r hierarchical clusters}
bands <- c("B04", "B07","B12","NDVI", "EVI")
samples_013015 <- samples[samples$tile == "013015",]
samples_013015_1y <-subset_by_date (samples_013015, "2018-07-28","2019-07-12")
hclusters <- clusters_by_bands_combination(samples_013015_1y, bands, 5)
```

The evaluation of the clustering uses distinct cluster and classification metrics to define the quality of each model. To calculate the classification metrics, we define a label for each cluster based on the majority, where the cluster label will be the class with more members in the cluster. Below is presented the evaluated metrics:

**Clustering indexes**

* RI: Rand Index.
* ARI: Adjusted Rand Index.
* J: Jaccard Index.
* FM: Fowlkes-Mallows
* VI: Soft Variation of Information
* Sil: Silhouette index
* D: Dunn index
* COP: COP index

**Classification metrics**

* ACC: Accuracy.
* ACC_F: Accuracy to Forest samples (Not used in voting).
* ACC_D: Accuracy to Forest samples (Not used in voting)..
* PREC: Precision.
* SENS: Sensitivity.
* SPEC: Specificity.
* F1: F1-Score.


In the code below, we calculate the metrics:

```{r metrics_models, results = FALSE, message=FALSE, warning=FALSE}
metrics_score <- models_metrics(hclusters, samples_013015_1y)
```

```{r show_metrics_models, results = 'asis', message=FALSE, warning=FALSE}
knitr::kable(metrics_score[1:11], caption="Best Models Pt1")
```

```{r show_metrics_models2, results = 'asis', message=FALSE, warning=FALSE}
knitr::kable(cbind(metrics_score[1],metrics_score[11:20]), caption="Best Models Pt2")
```
To select the best model based on the configuration bands, a voting schema using the clustering and classification metrics. Where each metric contributes with one single vote, the vote of the model depends on how the metric works. In some metrics, the target is to select the maximum between all band combinations by the given values; in others, the objective is to select the minimum value. In the minimum case, invert the metric value and select the maximum value measured. In the code below, we voted the best model, considering the number of bands.

```{r voting_best, results = FALSE, warning=FALSE}
best <- metrics_score[voting_best(metrics_score),]
best_clusters <- list()
best_clusters <- append(best_clusters, list(hclusters[[voting_best(metrics_score)]]))
```


```{r show_voting_best, results = 'asis', message=FALSE, warning=FALSE}
to_show <- cbind(best[1],best[14])
to_show <- cbind(to_show,best[19])
to_show <- cbind(to_show,best[20])
knitr::kable(to_show, caption="Best Model")
```

The code below selects the best clustering for each band combination. The code makes a voting schema to select the best model among the models with one, two (not done is the best configuration selected above), three, four, and five bands. At the end of the code, all the best models were recovered from the list `hclusters` and put in another list called `best` .


```{r best by n bands, results = 'asis', warning=FALSE}
best <- rbind(best, metrics_score[voting_nbands(metrics_score,1),])
best <-rbind(best, metrics_score[voting_nbands(metrics_score,3),])
best <-rbind(best, metrics_score[voting_nbands(metrics_score,4),])
best <-rbind(best, metrics_score[voting_nbands(metrics_score,5),])
best_clusters <- append(best_clusters, list(
  hclusters[[voting_nbands(metrics_score,1)]]))
best_clusters <- append(best_clusters, list(
  hclusters[[voting_nbands(metrics_score,3)]]))
best_clusters <- append(best_clusters, list(
  hclusters[[voting_nbands(metrics_score,4)]]))
best_clusters <- append(best_clusters, list(
  hclusters[[voting_nbands(metrics_score,5)]]))
```

```{r show_voting_best_models, results = 'asis', message=FALSE, warning=FALSE}
to_show <- cbind(best[1],best[14:20])
knitr::kable(to_show, caption="Best Models")
```

# Generalization Test

The generalization test analyzes how the best models perform over held-out test set samples. As shown, the original samples are  25 'BDC' tiles and cover the period  2018-07-28 to 2019-07-12. That represents time-series samples with 69 time steps or image observations.

* **BDC TILES**
```{r show tiles }
unique(samples$tile)
```
* **Time Series time steps**

```{r show time steps }
samples$time_series[[1]]$Index
```

In the section Bands Analysis, the training dataset (`samples_013015_1y`) used to generate the models comprises samples from the center tile (013015) of the study area. Also,  the train samples comprehend the period  2018-07-28 to 2019-07-12, the first year of the original samples.

The generalization analysis uses distinct areas and periods, generating a robust test set. The space generalization analysis uses samples at other tiles with the same period. The time generalization test uses a time series with distinct periods, more precisely, the next two years of original samples.

## Space generalization test

In this test, we want to verify how the models perform in other tiles and if the models perform well in the generalization test. Below are presented classification metrics to evaluate the performance of the models. The `prediction_test` function also save the predictions of each model into a csv file.

```{r spatial gen}
train_test_eval <- list()
for(i in 1:length(best_clusters)){
  pred <- prediction_test(samples,
                  best_clusters[[i]],
                  "2018-07-28",
                  "2019-07-12",
                  "../../data/csv/predicted/B04-B07-B12-NDVI-EVI",
                  "013015")
  train_test_eval <- append(train_test_eval, list(pred))
}
```

Below it present the classification metrics resulting of the 
```{r spatial gen show metrics, results = 'asis', message=FALSE, warning=FALSE}
to_show <- bind_rows(train_test_eval)
knitr::kable(to_show[3:11], caption="Spatial Generalization (Train Test)")
```

* Best Model in Spatial Generalization
```{r spatial gen best}
one_df <- bind_rows(train_test_eval)
only_test <- one_df[one_df$type == "Generalization(Test)",]
spatial_gen_best <- only_test[voting_best(only_test),]
spatial_gen_best[1:5]
```

* Best Model in Spatial Generalization by Tile
```{r spatial gen best by tile, results = 'asis', message=FALSE, warning=FALSE}
path <- "../../data/csv/predicted/B04-B07-B12-NDVI-EVI"
band <- spatial_gen_best$bands
start_date <- spatial_gen_best$start_date
end_date <- spatial_gen_best$end_date
file <- paste("cluster", band, sep = "_")
file <- paste(file, start_date, sep = "-")
file <- paste(file, end_date, sep = "-")
file <- paste(file, "csv", sep = ".")
file <- paste(path, file, sep = "/")
best_gen_predictions <- read.csv(file)
knitr::kable(head(best_gen_predictions), caption="Best Model Predictions (Train Test)")
```

```{r sg show best by tile, results = 'asis', message=FALSE, warning=FALSE}
metric_by_tile <- prediction_metrics_by_tile(
  best_gen_predictions,
  start_date,
  end_date,
  band)
metric_by_tile <- metric_by_tile[order(-metric_by_tile$ACC),]
knitr::kable(metric_by_tile, caption="Metrics by Tile (model B12)")
```

## Time generalization test

In this test we want verify how the models perform in other periods and verify if the models generalize. Below is presented classification metrics to evaluate the performance of the models.

### First Period 2019-07-28 to 2020-07-11

```{r time1 gen 2019 2020}
time_generalization_2019_2020 <- list()
for(i in 1:length(best_clusters)){
  pred <- prediction_test(samples,
                  best_clusters[[i]],
                  "2019-07-28",
                  "2020-07-11",
                  "../../data/csv/predicted/B04-B07-B12-NDVI-EVI/2019-2020")
  time_generalization_2019_2020 <- append(time_generalization_2019_2020, list(pred))
}
```

Below it present the classification metrics resulting of the 
```{r time1 gen show metrics, results = 'asis', message=FALSE, warning=FALSE}
to_show <- bind_rows(time_generalization_2019_2020)
knitr::kable(to_show[3:11], caption="Time Generalization 2019-2020")
```

```{r time1 gen best}
one_df <- bind_rows(time_generalization_2019_2020)
best <- one_df[voting_best(one_df),]
best[1:5]
```

```{r time1 gen best by tile, results = 'asis', message=FALSE, warning=FALSE}
path <- "../../data/csv/predicted/B04-B07-B12-NDVI-EVI/2019-2020"
band <- best$bands
start_date <- best$start_date
end_date <- best$end_date
file <- paste("cluster", band, sep = "_")
file <- paste(file, start_date, sep = "-")
file <- paste(file, end_date, sep = "-")
file <- paste(file, "csv", sep = ".")
file <- paste(path, file, sep = "/")
best_predictions_2019_2020 <- read.csv(file)
knitr::kable(head(best_predictions_2019_2020),
             caption="Best Model Predictions (2019-2020)")
```

```{r tg1 show best by tile, results = 'asis', message=FALSE, warning=FALSE}
metric_by_tile <- prediction_metrics_by_tile(
  best_predictions_2019_2020,
  start_date,
  end_date,
  band)
metric_by_tile <- metric_by_tile[order(-metric_by_tile$ACC),]
knitr::kable(metric_by_tile, caption="Metrics by Tile")
```

### Second Period 2021-07-12 to 2020-07-11

```{r time2 gen 2020 2021}
time_generalization_2020_2021 <- list()
for(i in 1:length(best_clusters)){
  pred <- prediction_test(samples,
                  best_clusters[[i]],
                  "2020-07-27",
                  "2021-07-12",
                  "../../data/csv/predicted/B04-B07-B12-NDVI-EVI/2020-2021")
  time_generalization_2020_2021 <- append(time_generalization_2020_2021, list(pred))
}
```

Below it present the classification metrics resulting of the 
```{r time2 gen show metrics, results = 'asis', message=FALSE, warning=FALSE}
to_show <- bind_rows(time_generalization_2020_2021)
knitr::kable(to_show[3:11], caption="Spatial Generalization (Train Test)")
```

```{r time2 gen best}
one_df <- bind_rows(time_generalization_2020_2021)
best <- one_df[voting_best(one_df),]
best[1:5]
```


```{r time2 gen best by tile, results = 'asis', message=FALSE, warning=FALSE}
path <- "../../data/csv/predicted/B04-B07-B12-NDVI-EVI/2020-2021"
band <- best$bands
start_date <- best$start_date
end_date <- best$end_date
file <- paste("cluster", band, sep = "_")
file <- paste(file, start_date, sep = "-")
file <- paste(file, end_date, sep = "-")
file <- paste(file, "csv", sep = ".")
file <- paste(path, file, sep = "/")
best_predictions_2020_2021 <- read.csv(file)
knitr::kable(head(best_predictions_2020_2021),
             caption="Best Model Predictions (2020-2021)")
```

```{r tg2 show best by tile, results = 'asis', message=FALSE, warning=FALSE}
metric_by_tile <- prediction_metrics_by_tile(
  best_gen_predictions,
  start_date,
  end_date,
  band)
metric_by_tile <- metric_by_tile[order(-metric_by_tile$ACC),]
knitr::kable(metric_by_tile, caption="Metrics by Tile (best model)")
```



## Deforestation Generalization test (DOING)

DEFORESTATION OTHER YEARS 2020-2021

```{r import samples deforestation 2019-2021 }
samples_deforestation_2019_2021 <- readRDS("../../data/rds/samples/2019-2021/dsamples-2019-2021.rds")
head(samples_deforestation_2019_2021)
```


```{r deforestation generalization 2019}
deforestation_2019_eval <- list()
start_dates <- list("2019-07-28","2020-07-27")
end_dates <- list("2020-07-11","2021-07-12")

for(d in 1:2){
  for(i in 1:length(best_clusters)){
  pred <- prediction_test(samples_deforestation_2019_2021,
                  best_clusters[[i]],
                  start_dates[[d]],
                  end_dates[[d]],
                  "../../data/csv/predicted/B04-B07-B12-NDVI-EVI/deforestation_2019")
  deforestation_2019_eval <- append(deforestation_2019_eval, list(pred))
}  
}

```
